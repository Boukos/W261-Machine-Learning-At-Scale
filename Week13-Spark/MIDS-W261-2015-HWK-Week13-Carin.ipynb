{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DATASCI W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Juanjo Carin**\n",
    "- [juanjose.carin@ischool.berkeley.edu](mailto:juanjose.carin@ischol.berkeley.com)\n",
    "- W261-2\n",
    "- Week 13\n",
    "- Submission date: 12/09/2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.5.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, Oct 19 2015 18:04:42)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = os.environ['SPARK_HOME'] = \\\n",
    "   '/HD/spark/'\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW13.1: Spark implementation of basic PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a basic Spark implementation of the iterative PageRank algorithm that takes sparse adjacency lists as input. Make sure that your implementation utilizes teleportation (1-damping/the number of nodes in the network), and further, distributes the mass of dangling nodes with each iteration so that the output of each iteration is correctly normalized (sums to 1).**\n",
    "\n",
    ">**[NOTE: The PageRank algorithm assumes that a random surfer (walker), starting from a random web page, chooses the next page to which it will move by clicking at random, with probability d, one of the hyperlinks in the current page. This probability is represented by a so-called ‘damping factor’ d, where d ∈ (0, 1). Otherwise, with probability (1 − d), the surfer jumps to any web page in the network. If a page is a dangling end, meaning it has no outgoing hyperlinks, the random surfer selects an arbitrary web page from a uniform distribution and “teleports” to that page]**\n",
    "\n",
    "**In your Spark solution, please use broadcast variables and caching to make sure your code is as efficient as possible.**\n",
    "\n",
    "**As you build your code, use the following test data to check you implementation:**\n",
    "\n",
    "**s3://ucb-mids-mls-networks/PageRank-test.txt**\n",
    "\n",
    "**Set the teleportation parameter  to 0.15 (1-d, where d, the damping factor is set to 0.85), and crosscheck your work with the true result, displayed in the first image in the Wikipedia article:**\n",
    "\n",
    "**https://en.wikipedia.org/wiki/PageRank**\n",
    "\n",
    "**and here for reference are the corresponding resulting PageRank probabilities:**\n",
    "\n",
    "    A,0.033\n",
    "    B,0.384\n",
    "    C,0.343\n",
    "    D,0.039\n",
    "    E,0.081\n",
    "    F,0.039\n",
    "    G,0.016\n",
    "    H,0.016\n",
    "    I,0.016\n",
    "    J,0.016\n",
    "    K,0.016\n",
    "\n",
    "**Run this experiment locally first. Report the local configuration that you used and how long in minutes and seconds it takes to complete your job.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time 0:31\n",
      "[('A', [])]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import time\n",
    "from operator import add\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lines = sc.textFile('PageRank-test.txt')\n",
    "\n",
    "def adj_lists(line):\n",
    "    line = line.strip().split('\\t')\n",
    "    source = line[0]\n",
    "    adj_list = ast.literal_eval(line[1]).keys()\n",
    "    yield str(source), adj_list\n",
    "adj_list = lines.\\\n",
    "    flatMap(lambda l: adj_lists(l)).\\\n",
    "    cache()\n",
    "\n",
    "#from collections import namedtuple\n",
    "#Adj_List = namedtuple('link', 'source sinks rank')\n",
    "#def adj_lists(line):\n",
    "#    line = line.strip().split('\\t')\n",
    "#    source = line[0]\n",
    "#    adj_list = ast.literal_eval(line[1]).keys()\n",
    "#    return Adj_List(str(source), adj_list, 0.1)\n",
    "#sources = lines.map(adj_lists)\n",
    "\n",
    "sinks = adj_list.\\\n",
    "    values().\\\n",
    "    flatMap(lambda line: line).\\\n",
    "    distinct().\\\n",
    "    map(lambda line: (line, [])).\\\n",
    "    cache()\n",
    "\n",
    "dangling = sinks.\\\n",
    "    subtractByKey(adj_list).\\\n",
    "    cache()\n",
    "\n",
    "total_adj_list = adj_list.\\\n",
    "    union(dangling).\\\n",
    "    cache()\n",
    "num_nodes = total_adj_list.count()\n",
    "\n",
    "def computeContribs(sinks, score):\n",
    "    \"\"\"Calculates URL contributions to the rank of other URLs.\"\"\"\n",
    "    num_sinks = len(sinks)\n",
    "    for s in sinks:\n",
    "        yield (s, score / num_sinks)\n",
    "        \n",
    "scores = total_adj_list.map(lambda (source, sinks): (source, 1.0/num_nodes))\n",
    "\n",
    "stop = time.time()\n",
    "exec_time = round(stop-start)\n",
    "print 'Execution time {}:{}'.format(str(int(exec_time/60)), \n",
    "                                    str(int(exec_time) - \n",
    "                                        60*int(exec_time/60)).zfill(2))\n",
    "\n",
    "print dangling.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 0\n",
      "E:\t0.329752066116\n",
      "B:\t0.316873278237\n",
      "C:\t0.0979338842975\n",
      "A:\t0.0592975206612\n",
      "D:\t0.0464187327824\n",
      "F:\t0.0464187327824\n",
      "H:\t0.0206611570248\n",
      "J:\t0.0206611570248\n",
      "G:\t0.0206611570248\n",
      "I:\t0.0206611570248\n",
      "K:\t0.0206611570248\n",
      "--------------\n",
      "ITERATION 1\n",
      "C:\t0.28756073128\n",
      "B:\t0.260690896569\n",
      "D:\t0.111648196844\n",
      "F:\t0.111648196844\n",
      "E:\t0.0994133483596\n",
      "A:\t0.0379464062109\n",
      "H:\t0.0182184447784\n",
      "J:\t0.0182184447784\n",
      "G:\t0.0182184447784\n",
      "I:\t0.0182184447784\n",
      "K:\t0.0182184447784\n",
      "--------------\n",
      "ITERATION 2"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for iteration in range(10):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    mass_dangling = dangling.\\\n",
    "        join(scores).\\\n",
    "        mapValues(lambda (sinks, score): score).\\\n",
    "        values().sum()\n",
    "\n",
    "    contribs = total_adj_list.\\\n",
    "        join(scores).\\\n",
    "        flatMap(lambda (source, (sinks, score)): computeContribs(sinks, score))\n",
    "    # Re-calculates URL ranks based on neighbor contributions.\n",
    "    new_scores = contribs.\\\n",
    "        reduceByKey(add).\\\n",
    "        mapValues(lambda score: (score + mass_dangling/num_nodes) * 0.85 \n",
    "                  + 0.15/num_nodes)\n",
    "    poor_scores = scores.\\\n",
    "        subtractByKey(new_scores).\\\n",
    "        mapValues(lambda score: mass_dangling/num_nodes * 0.85 \n",
    "                  + 0.15/num_nodes)\n",
    "    scores = new_scores.union(poor_scores)\n",
    "    print 'ITERATION {}'.format(str(iteration))\n",
    "    for (node, score) in scores.\\\n",
    "        map(lambda (node, score): (score, node)).\\\n",
    "        sortByKey(ascending = False).\\\n",
    "        map(lambda (score, node): (node, score)).\\\n",
    "        collect():\n",
    "        print '{}:\\t{}'.format(node, score)\n",
    "    print '--------------'\n",
    "\n",
    "stop = time.time()\n",
    "exec_time = round(stop-start)\n",
    "print 'Execution time {}:{}'.format(str(int(exec_time/60)), \n",
    "                                    str(int(exec_time) - 60*int(a/60)).zfill(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat this experiment on AWS. Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job. (in your notebook, cat the cluster config file)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 13.2: Applying PageRank to the Wikipedia hyperlinks network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run your Spark PageRank implementation on the Wikipedia dataset for 10 iterations, and display the top 100 ranked nodes (with alpha = 0.85).**\n",
    "\n",
    "NOTE: Wikipedia data is located on S3 at  s3://ucb-mids-mls-networks/wikipedia/\n",
    "\n",
    "+ s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt # Graph\n",
    "+ s3://ucb-mids-mls-networks/wikipedia/indices.txt               # Page titles and page Ids\n",
    "\n",
    "**Run your PageRank implementation on the Wikipedia dataset for 50 iterations, and display the top 100 ranked nodes (with teleportation factor of 0.15).**\n",
    "\n",
    "\n",
    "**Plot the pagerank values for the top 100 pages resulting from the 50 iterations run. Then plot the pagerank values for the same 100 pages that resulted from the 10 iterations run.  Comment on your findings.  Have the top 100 ranked pages changed? Have the pagerank values changed? Explain.**\n",
    "\n",
    "**Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from operator import add\n",
    "\n",
    "lines = sc.textFile('PageRank-test.txt')\n",
    "\n",
    "def adj_lists(line):\n",
    "    line = line.strip().split('\\t')\n",
    "    source = line[0]\n",
    "    adj_list = ast.literal_eval(line[1]).keys()\n",
    "    yield str(source), adj_list\n",
    "adj_list = lines.\\\n",
    "    flatMap(lambda l: adj_lists(l)).cache()\n",
    "\n",
    "#from collections import namedtuple\n",
    "#Adj_List = namedtuple('link', 'source sinks rank')\n",
    "#def adj_lists(line):\n",
    "#    line = line.strip().split('\\t')\n",
    "#    source = line[0]\n",
    "#    adj_list = ast.literal_eval(line[1]).keys()\n",
    "#    return Adj_List(str(source), adj_list, 0.1)\n",
    "#sources = lines.map(adj_lists)\n",
    "\n",
    "sinks = adj_list.\\\n",
    "    values().\\\n",
    "    flatMap(lambda line: line).\\\n",
    "    distinct().\\\n",
    "    map(lambda line: (line, []))\n",
    "\n",
    "dangling_nodes = sinks.\\\n",
    "    subtractByKey(adj_list).\\\n",
    "    cache()\n",
    "\n",
    "total_adj_list = adj_list.\\\n",
    "    union(dangling_nodes).\\\n",
    "    cache()\n",
    "num_nodes = total.count()\n",
    "\n",
    "def computeContribs(sinks, score):\n",
    "    \"\"\"Calculates URL contributions to the rank of other URLs.\"\"\"\n",
    "    num_sinks = len(sinks)\n",
    "    for s in sinks:\n",
    "        yield (s, score / num_sinks)\n",
    "        \n",
    "scores = total_adj_list.map(lambda (source, sinks): (source, 1.0/num_nodes))\n",
    "\n",
    "total = total_adj_list.\\\n",
    "    map(lambda (source, adj_list): (source, \n",
    "                                    [adj_list, 1.0/num_nodes]))\n",
    "dangling = dangling_nodes.\\\n",
    "    map(lambda (source, adj_list): (source, \n",
    "                                    [adj_list, 1.0/num_nodes]))\n",
    "\n",
    "for iteration in range(10):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    mass_dangling = dangling.\\\n",
    "        mapValues(lambda (sinks, score): score).\\\n",
    "        values().sum()\n",
    "    contribs = total.\\\n",
    "        flatMapValues(lambda (sinks, score): computeContribs(sinks, score))\n",
    "    # Re-calculates URL ranks based on neighbor contributions.\n",
    "    new_scores = contribs.\\\n",
    "        reduceByKey(add).\\\n",
    "        mapValues(lambda score: (score + mass_dangling/num_nodes) * 0.85 \n",
    "                  + 0.15/num_nodes)\n",
    "    poor_scores = scores.\\\n",
    "        subtractByKey(new_scores).\\\n",
    "        mapValues(lambda score: mass_dangling/num_nodes * 0.85 \n",
    "                  + 0.15/num_nodes)\n",
    "    scores = new_scores.union(poor_scores)\n",
    "    print 'ITERATION {}'.format(str(iteration))\n",
    "    for (node, score) in scores.\\\n",
    "        map(lambda (node, score): (score, node)).\\\n",
    "        sortByKey(ascending = False).\\\n",
    "        map(lambda (score, node): (node, score)).\\\n",
    "        collect():\n",
    "        print '{}:\\t{}'.format(node, score)\n",
    "    print '--------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, sys\n",
    "from operator import add\n",
    "\n",
    "\n",
    "def computeContribs(urls, rank):\n",
    "    \"\"\"Calculates URL contributions to the rank of other URLs.\"\"\"\n",
    "    num_urls = len(urls)\n",
    "    for url in urls: yield (url, rank / num_urls)\n",
    "\n",
    "\n",
    "def parseNeighbors(urls):\n",
    "    \"\"\"Parses a urls pair string into urls pair.\"\"\"\n",
    "    parts = re.split(r'\\s+', urls)\n",
    "    return parts[0], parts[1]\n",
    "\n",
    "\n",
    "\n",
    "lines = sc.textFile('prueba.txt')\n",
    "print lines.collect()\n",
    "\n",
    "# Loads all URLs from input file and initialize their neighbors.\n",
    "links = lines.map(lambda urls: parseNeighbors(urls)).groupByKey().cache()\n",
    "\n",
    "    # Loads all URLs with other URL(s) link to from input file and initialize ranks of them to one.\n",
    "scores = links.map(lambda (source, sinks): (source, 0.1))\n",
    "print scores.collect()\n",
    "    # Calculates and updates URL ranks continuously using PageRank algorithm.\n",
    "for iteration in xrange(int(5)):\n",
    "    # Calculates URL contributions to the rank of other URLs.\n",
    "    \n",
    "    \n",
    "    #links.subtractByKey(ranks).keys().collect()\n",
    "    \n",
    "    \n",
    "    contribs = links.subtractByKey(scores).flatMap(lambda (url, (urls, rank)):\n",
    "        computeContribs(urls, rank))\n",
    "    total_mass = ranks.values().sum()\n",
    "    print total_mass\n",
    "    total_mass = 0\n",
    "     # Re-calculates URL ranks based on neighbor contributions.\n",
    "    scores = contribs.reduceByKey(add).mapValues(lambda score: (score + total_mass/11) * 0.85 + 0.15/11)\n",
    "# Collects all URL ranks and dump them to console.\n",
    "for (node, score) in scores.collect():\n",
    "    print \"%s has rank: %s.\" % (node, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print links.cogroup(scores).map(lambda (u, (u2,s)): s)#.collect()\n",
    "\n",
    "print links.join(ranks).keys().collect()\n",
    "print links.join(ranks).flatMap(lambda (url, (urls, rank)): urls).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print links.subtractByKey(ranks).keys().collect() # SOURCES, NOT SINKS\n",
    "print ranks.subtractByKey(links).keys().collect() # SINKS, NOT SOURCES = DANGLING\n",
    "dangling = ranks.subtractByKey(links)\n",
    "print dangling.values().sum()\n",
    "#result = pairs.filter(lambda keyValue: len(keyValue[1]) < 20)\n",
    "print links.keys().collect()\n",
    "print ranks.keys().collect()\n",
    "print '+++++'\n",
    "print links.leftOuterJoin(ranks).keys().collect()\n",
    "print links.rightOuterJoin(ranks).keys().collect()\n",
    "print '+++++'\n",
    "print ranks.values().sum()\n",
    "print ranks.count()\n",
    "print links.count()\n",
    "print '+++++'\n",
    "print lines.map(lambda urls: parseNeighbors(urls)).count()\n",
    "print lines.map(lambda urls: parseNeighbors(urls)).distinct().count()\n",
    "\n",
    "print lines.map(lambda urls: parseNeighbors(urls)).collect()\n",
    "print lines.map(lambda urls: parseNeighbors(urls)).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 2 functions:\n",
    "\n",
    "1. One to get the cluster centroid closer to any point in the dataset. It calls the `value` on the broadcast variable `centroidsBroadcast`, as its argument is each of the datapoints.\n",
    "\n",
    "2. An optional function to plot the current centroids. Its argument will be the broadcast centroids, so there's no need to explicitly mention them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Calculate which class each data point belongs to\n",
    "def nearest_centroid(line):\n",
    "    x = np.array([float(f) for f in line.split(',')])\n",
    "    #### USE BROADCAST VALUES\n",
    "    closest_centroid_idx = np.sum((x - centroidsBroadcast.value)**2, axis=1).\\\n",
    "        argmin()\n",
    "    return (closest_centroid_idx,(x,1))\n",
    "\n",
    "#plot centroids and data points for each iteration\n",
    "def plot_iteration(means):\n",
    "    plt.plot(samples1[:, 0], samples1[:, 1], '.', color = 'blue')\n",
    "    plt.plot(samples2[:, 0], samples2[:, 1], '.', color = 'blue')\n",
    "    plt.plot(samples3[:, 0], samples3[:, 1],'.', color = 'blue')\n",
    "    plt.plot(means[0][0], means[0][1],'*',markersize =10,color = 'red')\n",
    "    plt.plot(means[1][0], means[1][1],'*',markersize =10,color = 'red')\n",
    "    plt.plot(means[2][0], means[2][1],'*',markersize =10,color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The driver makes use of both functions above. It first creates K random centroids...that are broadcasted to all executors (probably just 1 in this toy example), and then updates (**broadcasts**) this broadcast variable in each iteration, as the datapoints closer to each centroid change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "# Initialization: initialization of parameter is fixed to show an example\n",
    "centroids = np.array([[0.0,0.0],[2.0,2.0],[0.0,7.0]])\n",
    "#### BROADCAST INITIAL CENTROIDS\n",
    "centroidsBroadcast = sc.broadcast(centroids)\n",
    "\n",
    "D = sc.textFile(\"./data.csv\").cache()\n",
    "iter_num = 0\n",
    "for i in range(10):  \n",
    "    res = D.map(nearest_centroid).\\\n",
    "        reduceByKey(lambda x,y : (x[0]+y[0],x[1]+y[1])).collect()\n",
    "    res = sorted(res,key = lambda x : x[0])  #sort based on clusted ID\n",
    "    centroids_new = np.array([x[1][0]/x[1][1] for x in res])\n",
    "        #divide by cluster size\n",
    "    #### USE BROADCAST VALUE TO CHECK CONDITION\n",
    "    if np.sum(np.absolute(centroids_new-centroidsBroadcast.value))<0.01:\n",
    "        break\n",
    "    print \"Iteration\" + str(iter_num)\n",
    "    iter_num = iter_num + 1 \n",
    "    #### UPDATE CENTROIDS AND BROADCAST\n",
    "    centroidsBroadcast = sc.broadcast(centroids_new)\n",
    "    #### PRINT NEW CENTROIDS\n",
    "    print centroidsBroadcast.value\n",
    "    #### PLOT NEW CENTROIDS\n",
    "    plot_iteration(centroidsBroadcast.value)\n",
    "print \"Final Results:\"\n",
    "print centroidsBroadcast.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW11.1: Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.1.1\n",
    "**In the context of binary classification problems, does the linear SVM learning algorithm yield the same result as a L2 penalized logistic regresssion learning algorithm?**\n",
    "\n",
    "**In your reponse, please discuss the loss functions, and the learnt models, and separating surfaces between the two classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily, though if we let both algorithms converge the results (the hyperplanes, and hence the predictions) should be quite similar.\n",
    "\n",
    "The separatign surface in both algorithms is an hyperplane (specified by an equation of the type $w^T x$, though in the case of the Logistic Regression it represents the logit of the likelihood, i.e., hte logarithm of the Odds Ratio), but the SVM does not intend to minimize any loss function (as the Logistic Regression does), but only the regularization term (similar to the L2 regularization term in the Logistic Regression; in the case of a SVM, the regularization term would be inversely proportional to the margin.\n",
    "\n",
    "To demonstrate this, **see the addendum at the end of HW11.3.3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.1.2\n",
    "**In the context of binary classification problems, does the linear SVM learning algorithm yield the same result as a perceptron learning algorithm?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Same answer as before: the final result (the weights, and hence the decision boundary or hyperplane that makes datapoints to fall into one category or the other) will be similar but not necessarily equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW11.2: Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.2.1\n",
    "**In the context of logistic regression describe and define three flavors of penalized loss functions. Are these all supported in Spark MLLib (include online references to support your answers)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Logistic Regression the objective function (or penalized loss function) we want to minimize is defined as:\n",
    "\n",
    "$$J(w)=\\sum_iL(\\mathbf{w},\\mathbf{x_i},y_i)+\\lambda R(\\mathbf{w}) = \\sum_i log(1+e^{-y \\mathbf{w}^T \\mathbf{x}_i})+\\lambda R(\\mathbf{w})$$\n",
    "\n",
    "where $y \\in \\{-1,+1\\}$ (the definition of the loss term $L(\\mathbf{w},\\mathbf{x_i},y_i)$ is different when $y \\in \\{0,+1\\}$).\n",
    "\n",
    "Three flavors of the regularization term would be:\n",
    "1. **Lasso**, where the L1 norm lf $w$ is used (as $R(\\mathbf{w})$: $\\left \\|  \\mathbf{w}\\right \\|_1$\n",
    "    - It can help promote sparsity in weights leading to smaller and more interpretable models, the latter of which can be useful for feature selection. \n",
    "2. **Ridge**, where the L2 norm of $w$ is used: $\\frac{1}{2}\\left \\|  \\mathbf{w}\\right \\|_2^2$\n",
    "    - Generally easier to solve than L1-regularized due to smoothness.\n",
    "3. **Elastic net**, a (weighted) combination of the previous two ones: $\\alpha \\left \\|  w\\right \\|_1 + (1-\\alpha)\\frac{1}{2}\\left \\|  w\\right \\|_2^2$\n",
    "\n",
    "All of them are supported in Spark MLLib: http://spark.apache.org/docs/latest/mllib-linear-methods.html#loss-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.2.2\n",
    "**Descibe probabilitic interpretations of the L1 and L2 priors for penalized logistic regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it simple, I will use the case in which there are only 2 features or independent variables.\n",
    "\n",
    "In Logistic Regression we want to maximize the likelihood of a class given the independent variables: $\\Pr(y=+1 \\mid \\mathbf{x})$. The loss term is the inverse of (the logit of) that prior, and hence we want to minimize it. That loss term is a function of $w_1$ and $w_2$ and thus defined in $\\mathbb{R}^2$.\n",
    "\n",
    "The L1 regularization term adds a constraint in finding the minimum of $L(\\mathbf{w},\\mathbf{x},y)$: $|w_1| + |w_2|$ cannot exceed a certain value (i.e., $(w_1, w_2)$ is inside a \"diamond\". That's like adding a prior to the weights: instead of minimizing the cost function (i.e., maximizing the likelihood) given the training data, we are maximizing the likelihood given the *additional information bias*.\n",
    "\n",
    "The same applies to the L2 regularization term, but in this case the constraint puts $(w_1,w_2)$ inside a circle ($|w_1|^2+|w_2|^2$ cannot exceed a certain value).\n",
    "\n",
    "-----\n",
    "\n",
    "L1 and L2 are also called Laplacian and Gaussian priors, respectively. The Laplacian pdf is similar to the Gaussian but it uses the L1 norm (or Manhattan distance) rather than the L2 norm (or Euclidean distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW11.3: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.3.1\n",
    "**Generate 2 sets of linearly separable data with 100 data points each using the data generation code provided below and plot each in separate plots. Call one the training set and the other the testing set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data set will have 100 points, 50 in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(n):\n",
    "    \"\"\" \n",
    "    generates a 2D linearly separable dataset with n samples. \n",
    "    The third element of the sample is the label\n",
    "    \"\"\"\n",
    "    from numpy.random import rand ## Seems like this line was missing    \n",
    "    xb = (rand(n)*2-1)/2-0.5\n",
    "    yb = (rand(n)*2-1)/2+0.5\n",
    "    xr = (rand(n)*2-1)/2+0.5\n",
    "    yr = (rand(n)*2-1)/2-0.5\n",
    "    inputs = []\n",
    "    for i in range(len(xb)):\n",
    "        inputs.append([xb[i],yb[i],1])\n",
    "        inputs.append([xr[i],yr[i],-1])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    data = generateData(50)\n",
    "    data = np.array([np.array(xi) for xi in data])\n",
    "    plt.plot(data[data[:,2]==1, 0], data[data[:,2]==1, 1], \n",
    "               'o', color = 'blue')\n",
    "    plt.plot(data[data[:,2]==-1, 0], data[data[:,2]==-1, 1], \n",
    "               'o', color = 'red')\n",
    "    if i == 0:\n",
    "        training_set = data\n",
    "        plt.title('TRAINING SET')\n",
    "    else:\n",
    "        testing_set = data\n",
    "        plt.title('TESTING SET')\n",
    "    plt.plot([-1,1], [-1,1], linewidth=2.0, color = 'black')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.3.2\n",
    "**Modify this data generation code to generating non-linearly separable training and testing datasets (with approximately 10% of the data falling on the wrong side of the separating hyperplane. Plot the resulting datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 100 points in each dataset, approximately (well, exactly in this case) 10% (5 in the $x>0, y<0$ region and 5 in the $x<0, y>0$ region) will be assigned the wrong label.\n",
    "\n",
    "Those points can be anywhere in the wrong region (I was not sure if they should be more likely near the origin (and hence the separating hyperplane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData2(n):\n",
    "    \"\"\" \n",
    "    generates a 2D NON-linearly separable dataset with n samples. \n",
    "    The third element of the sample is the label\n",
    "    \"\"\"\n",
    "    from numpy.random import rand ## Seems like this line was missing    \n",
    "    xb = (rand(n)*2-1)/2-0.5\n",
    "    yb = (rand(n)*2-1)/2+0.5\n",
    "    xr = (rand(n)*2-1)/2+0.5\n",
    "    yr = (rand(n)*2-1)/2-0.5\n",
    "    inputs = []\n",
    "    wrong = 0.1\n",
    "    for i in range(int(round(len(xb)*wrong))):\n",
    "        ## FIRST 10% OF THE GENERATED POINTS ARE ASSIGNED THE WRONG LABEL\n",
    "        inputs.append([xb[i],yb[i],-1])\n",
    "        inputs.append([xr[i],yr[i],1])\n",
    "    for i in range(int(round(len(xb)*wrong)), len(xb)):\n",
    "        inputs.append([xb[i],yb[i],1])\n",
    "        inputs.append([xr[i],yr[i],-1])\n",
    "    #inputs = np.array([np.array(xi) for xi in inputs])\n",
    "    #np.random.shuffle(inputs)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "for i in range(2):\n",
    "    data = generateData2(50)\n",
    "    data = np.array([np.array(xi) for xi in data])\n",
    "    plt.plot(data[data[:,2]==1, 0], data[data[:,2]==1, 1], \n",
    "               'o', color = 'blue')\n",
    "    plt.plot(data[data[:,2]==-1, 0], data[data[:,2]==-1, 1], \n",
    "               'o', color = 'red')\n",
    "    if i == 0:\n",
    "        training_set = data\n",
    "        with open('training_set.csv', 'wb') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "        plt.title('TRAINING SET')\n",
    "    else:\n",
    "        testing_set = data\n",
    "        with open('testing_set.csv', 'wb') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "        plt.title('TESTING SET')\n",
    "    plt.plot([-1,1], [-1,1], linewidth=2.0, color = 'black')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: For the remainder of this problem please use the non-linearly separable training and testing datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.3.3\n",
    "**Using MLLib  train up a LASSO logistic regression model with the training dataset and evaluate with the testing set. What a good number of iterations for training the logistic regression model? Justify with plots and words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOME COMMENTS ABOUT THE CONVERGENCE CRITERIA (that I've chosen):\n",
    "\n",
    "Let's assume that at a certain iteration, we have the following hyperplane equation: $\\pi_1: w_1 x_1 + w_2 x_2 + w_3 = 0$.\n",
    "\n",
    "For another hyperplane, $\\pi_2: w_3 x_1 + w_4 x_2 + w_5 = 0$ (say the one in the following iteration), to be the same, the following condition must be met:\n",
    "\n",
    "$$\\exists \\gamma  / \\gamma \\pi_2 = \\pi_1$$\n",
    "\n",
    "I.e.,\n",
    "\n",
    "$$\\left\\{\\begin{matrix}\n",
    "\\gamma = \\frac{w_1}{w_4}\\\\ \n",
    "\\gamma = \\frac{w_2}{w_5}\\\\ \n",
    "\\gamma = \\frac{w_4}{w_6}\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "I.e, we don't care if a weight doubles from one iteration to the next, as long as the same happens with all the weights.\n",
    "\n",
    "To relax the condition, I'll consider that 2 hyperplanes are (almost) the same if the 3 relations above are very similar, i.e.\n",
    "\n",
    "$$\\frac{w_1}{w_4} \\simeq \\frac{w_2}{w_5} \\simeq \\frac{w_3}{w_6}$$\n",
    "\n",
    "Let's say that 2 numbers are similar if their ratio is lower than 1.01 or higher than 0.99 (they have increased or decreased 1% at max), i.e.,\n",
    "\n",
    "$$\\frac{\\frac{w_i}{w_{i+3}}}{\\frac{w_j}{w_{j+3}}} \\in [0.99,1.01]$$\n",
    "\n",
    "for all possible combinations of $i,j \\in \\{1,N\\}$, where $N$ is the number of features plus 1.\n",
    "\n",
    "This criterion is a bit arbitrary, and it does not ensure that we have achieved the lowest misclassification error possible. But it can be made more strict just by changing that 1% by say 0.1% (that would be the way to go, rather than imposing any criterion about the misclassification error, which we would not know in a real case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### EXAMPLE\n",
    "prev_w = np.arange(1,4)\n",
    "print 'Previous w:\\t\\t\\t', prev_w\n",
    "w = prev_w * (2 + np.random.normal(size=3)/100)\n",
    "print 'New w:\\t\\t\\t\\t', w\n",
    "ratio = w/prev_w\n",
    "print 'Gammas:\\t\\t\\t\\t', ratio\n",
    "## We have to compare all possible ratios: 1 with 2, 1 with 3, 2 with 3\n",
    "import itertools\n",
    "comb = [x for x in itertools.combinations(range(len(w)),2)]\n",
    "ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) for (i,j) in comb])\n",
    "print 'Ratios of gammas:\\t\\t', ratio_of_ratio\n",
    "condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "print 'Check condition of ratios:\\t', condition\n",
    "print 'Check overall condition:\\t', condition.all(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, \\\n",
    "    LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import itertools\n",
    "\n",
    "iterations = 20\n",
    "## Define equally spaced colors for each iteration\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, iterations+1))\n",
    "\n",
    "def parsePoint(line):\n",
    "    ## Change labels to 0 and 1 (rather than -1 and 1)\n",
    "        ## Those are the values accepted by MLLib\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    if values[2] == -1:\n",
    "        y = 0\n",
    "    elif values[2] == 1:\n",
    "        y = 1\n",
    "    return LabeledPoint(y, values[:2])\n",
    "\n",
    "## Load and cache both sets\n",
    "training = sc.textFile(\"training_set.csv\")\n",
    "testing = sc.textFile(\"testing_set.csv\")\n",
    "training = training.map(parsePoint).cache()\n",
    "testing = testing.map(parsePoint).cache()\n",
    "\n",
    "## Draw the true hyperplane\n",
    "x1 = [-1, 1]\n",
    "w = [-1, 1, 0]\n",
    "x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x1, x2, 'b', label=\"True line\", linewidth=2.0, color = 'black', \n",
    "         linestyle='--')\n",
    "\n",
    "prev_w = [float('inf')]*3\n",
    "#prev_Err = float('inf')\n",
    "\n",
    "## Try a few iterations (no need for more in this case)\n",
    "for it in range(iterations+1):\n",
    "    print 'Iteration: {}'.format(it)\n",
    "    # Build the model (Lasso/L1, lambda = 0.5)\n",
    "    model = LogisticRegressionWithLBFGS.train(training, regType=\"l1\", \n",
    "                                              regParam=0.01, \n",
    "                                              intercept = True, \n",
    "                                              iterations = it)\n",
    "    print model\n",
    "\n",
    "    # Evaluating the model on testing data\n",
    "    labelsAndPreds = testing.\\\n",
    "        map(lambda p: (p.label, model.predict(p.features)))\n",
    "    Err = labelsAndPreds.\\\n",
    "        filter(lambda (v, p): v != p).count() / float(testing.count())\n",
    "    w = [model.weights[0], model.weights[1], model.intercept]\n",
    "    x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "    ## Plot the hyperplanes\n",
    "    plt.plot(x1, x2, color=colors[it], label=\"After {} iterations\".\n",
    "             format(str(it)), linewidth=1.5)\n",
    "    \n",
    "    ## Stop when it converges\n",
    "    ## Convergence is decided based on the relative change of the weights\n",
    "        ## An absolute change makes no sense since we don't know a priori\n",
    "            ## how large the weights will be\n",
    "        ## The criteria I've chosed is than, on average, the weight vector\n",
    "            ## has converged when each weight, on average is less than 33%\n",
    "            ## above/below its previous value\n",
    "    #if sum([abs(float(a)/b) if abs(float(a)/b) > 1 else abs(float(b)/a) \n",
    "    #        for (a,b) in zip(w,prev_w)]) < len(w)+1 \\\n",
    "    #    and trainErr == prev_trainErr:\n",
    "        ## NEW CRITERIA: None the weights (incl. the intercept) is 25%\n",
    "            ## above/below its previous value\n",
    "    #if max([abs(float(a)/b) if abs(float(a)/b) > 1 else abs(float(b)/a) \n",
    "    #        for (a,b) in zip(w,prev_w)]) < 1.25 and trainErr == prev_trainErr:\n",
    "    #    break\n",
    "    \n",
    "    comb = [c for c in itertools.combinations(range(len(w)),2)]\n",
    "    ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) \n",
    "                               for (i,j) in comb])\n",
    "    condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "    if condition.all(axis=0):\n",
    "        break\n",
    "    \n",
    "    prev_w = w\n",
    "    #prev_Err = Err\n",
    "    print \"Testing Error: {}\".format(str(Err))\n",
    "    print '------------------'\n",
    "\n",
    "## Last iteration's results\n",
    "print \"Testing Error: {}\".format(str(Err))\n",
    "print '------------------'\n",
    "print 'CONVERGENCE AFTER {} ITERATIONS'.format(it)\n",
    "print 'Relative change of weights (incl. intercept) between iterations '\\\n",
    "    '{} and {}:\\n\\t{}'.format(it-1, it, [a/b for (a,b) in zip(w,prev_w)])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, borderaxespad=0.)\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-1,1])\n",
    "axes.set_xlim([-1,1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight vector is relatively close to its final value just after the 2nd iteration. And at that point we've already achieved the lowest testing error possible (10%). The convergence criteria is met after 10 iterations.\n",
    "\n",
    "Do note that the values of the weights (and the results commented above) are highly dependent on the value of `regParam` ($\\lambda$; I used $\\lambda = 0.01$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional\n",
    "Comparison between Logistic Regression and SVM (using Ridge instead of Lasso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "\n",
    "for i in range(10):\n",
    "    print 'Iteration: {}'.format(i)\n",
    "    # Build the model\n",
    "    model_LR = LogisticRegressionWithLBFGS.train(training, regType=\"l2\", \n",
    "                                                 regParam=0.01, \n",
    "                                                 intercept = True, \n",
    "                                                 iterations = i)\n",
    "    \n",
    "    model_SVM = SVMWithSGD.train(training, regType=\"l2\", regParam=0.01, \n",
    "                                 intercept = True, iterations = i)\n",
    "    print 'LogReg:\\t{}'.format(model_LR)\n",
    "    print 'SVM:\\t{}'.format(model_SVM)\n",
    "\n",
    "    # Evaluating the model on training data\n",
    "    labelsAndPreds_LR = testing.\\\n",
    "        map(lambda p: (p.label, model_LR.predict(p.features)))\n",
    "    labelsAndPreds_SVM = testing.\\\n",
    "        map(lambda p: (p.label, model_SVM.predict(p.features)))\n",
    "    trainErr_LR = labelsAndPreds_LR.\\\n",
    "        filter(lambda (v, p): v != p).count() / float(testing.count())\n",
    "    trainErr_SVM = labelsAndPreds_SVM.\\\n",
    "        filter(lambda (v, p): v != p).count() / float(testing.count())\n",
    "    print \"Testing Error:\"\n",
    "    print \"\\tLR:\\t{}\".format(str(trainErr_LR))\n",
    "    print \"\\tSVM:\\t{}\".format(str(trainErr_SVM))\n",
    "    print '-------------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing error is highly dependent on the value of $\\lambda$, especially in the case of the SVM (which seems to converge also more slowly).\n",
    "\n",
    "Though not plotted here, the final hyperplanes are quite similar: $w_0 \\simeq  0, w_1 \\simeq -w2$, so the lines are both diagonals almost crossing the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.3.4\n",
    "\n",
    "**Derive and implement in Spark a weighted  LASSO logistic regression. Implement a convergence test of your choice to check for termination within your training algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is general purpose: we just have to weight each point before passing it to the function as an argument. So I start analyzing the results of the unweighted version.\n",
    "\n",
    "The convergence test is the same as before.\n",
    "\n",
    "The function already checks the misclassification error, but for the moment we'll test the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logRegressionGDReg(training, testing, wInitial=None, learningRate=0.05, \n",
    "                       iterations=50, regParam=0.01, regType=None):\n",
    "\n",
    "    ## Draw the true hyperplane\n",
    "    x1 = [-1, 1]\n",
    "    w = [-1, 1, 0]\n",
    "    x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(x1, x2, 'b', label=\"True line\", linewidth=2.0, color = 'black', \n",
    "             linestyle='--')\n",
    "\n",
    "    featureLen = len(training.take(1)[0].x)\n",
    "    n = training.count()\n",
    "    if wInitial is None:\n",
    "        w = np.random.normal(size=featureLen)\n",
    "        #w = [0]*featureLen\n",
    "        #w[-1] = 1\n",
    "        #w = np.array(w)\n",
    "    else:\n",
    "        w = wInitial\n",
    "    prev_w = np.array([float('inf')]*featureLen)\n",
    "    #prev_Err = float('inf')\n",
    "    Err_vector = []\n",
    "    convergence = False\n",
    "    \n",
    "    x1 = [-1,1]\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, iterations/25+1))\n",
    "    \n",
    "    for it in range(iterations+1):\n",
    "        wBroadcast = sc.broadcast(w)\n",
    "        gradient = training.\\\n",
    "            map(lambda p: (1 / (1 + np.exp(-p.y * np.dot(wBroadcast.value, \n",
    "                                                         p.x)))-1) * p.y * \n",
    "                np.array(p.x)).\\\n",
    "            reduce(lambda a, b: a + b)\n",
    "        errors = testing.\\\n",
    "            map(lambda p: p.y != (np.dot(wBroadcast.value, p.x)>0).\n",
    "                astype(int)*2 - 1).\\\n",
    "            filter(lambda wx: wx == True).count()\n",
    "        Err = float(errors) / n\n",
    "        Err_vector.append(Err)\n",
    "        \n",
    "        if Err == 0.1 and convergence == False:\n",
    "            print '+++++++++++++++++++++++++++++++++++++++'\n",
    "            print 'Minimum error achieved at iteration {}'.format(it)\n",
    "            print 'Ratio of weights at this iteration:'\n",
    "            print '\\t{}'.format(ratio_of_ratio)\n",
    "            print '+++++++++++++++++++++++++++++++++++++++'\n",
    "            convergence = True\n",
    "\n",
    "        if regType == \"Ridge\":\n",
    "            wReg = w * 1\n",
    "            wReg[-1] = 0 \n",
    "        elif regType == \"Lasso\":\n",
    "            wReg = w * 1\n",
    "            wReg[-1] = 0 \n",
    "            wReg = (wReg>0).astype(int) * 2-1\n",
    "        else:\n",
    "            wReg = np.zeros(w.shape[0])\n",
    "        gradient = gradient + regParam * wReg\n",
    "        ## Gradient: GD of Squared Error+ GD of regularized term \n",
    "        w = w - learningRate * gradient / n\n",
    "        if it % 25 == 0 and it != 0:\n",
    "            print 'Iteration {}'.format(str(it))\n",
    "            print '\\tWeights:\\t{}'.format(w)\n",
    "            print '\\tError rate:\\t{}'.format(str(Err))\n",
    "            print '----------------------------'\n",
    "            x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "            ## Plot the hyperplanes\n",
    "            plt.plot(x1, x2, color=colors[it/25], label=\"After {} iterations\".\n",
    "                 format(str(it)), linewidth=1.5)\n",
    "        \n",
    "        ## STOP IF CONVERGENCE\n",
    "        comb = [c for c in itertools.combinations(range(len(w)),2)]\n",
    "        ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) \n",
    "                                   for (i,j) in comb])\n",
    "        condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "        if condition.all(axis=0):\n",
    "            if Err != 0.1:\n",
    "                if convergence == False:\n",
    "                    print '+++++++++++++++++++++++++++++++++++++++++++'\n",
    "                    print 'Converge criterion met after {} iterations'\\\n",
    "                        '\\nbut lowest error not achieved yet.'.format(str(it))\n",
    "                    print '+++++++++++++++++++++++++++++++++++++++++++'\n",
    "                    convergence = True\n",
    "            else:\n",
    "                print 'Converged after {} iterations.'.format(str(it))\n",
    "                print '\\tWeights:\\t{}'.format(w)\n",
    "                print '\\tError rate:\\t{}'.format(str(Err))\n",
    "                x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "                plt.plot(x1, x2, color='red', label=\"After {} iterations\".\n",
    "                         format(str(it)), linewidth=2.0)\n",
    "                plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, \n",
    "                           borderaxespad=0.)\n",
    "                plt.xlabel(\"x1\")\n",
    "                plt.ylabel(\"x2\")\n",
    "                axes = plt.gca()\n",
    "                axes.set_xlim([-1,1])\n",
    "                axes.set_ylim([-1,1])\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "                break\n",
    "        prev_w = w\n",
    "        #prev_Err = Err\n",
    "        if it == iterations:\n",
    "            print 'Not enough iterations to converge'\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, \n",
    "                       borderaxespad=0.)\n",
    "            plt.xlabel(\"x1\")\n",
    "            plt.ylabel(\"x2\")\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,1])\n",
    "            axes.set_ylim([-1,1])\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "    return Err_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Point = namedtuple('Point', 'x y')\n",
    "\n",
    "def readPoint(line):\n",
    "    d = line.split(',')\n",
    "    x = [float(i) for i in d[:2]]\n",
    "    x.append(1.0)  #bias term\n",
    "    return Point(x, float(d[2]))\n",
    "\n",
    "train = sc.textFile('training_set.csv').map(readPoint).cache()\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "Error_Vector_LR1 = logRegressionGDReg(train, train, iterations=200, \n",
    "                                      regParam=0.01, regType=\"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iter = len(Error_Vector_LR1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_LR1)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "axes = plt.gca()\n",
    "#axes.set_ylim([np.floor(min(Error_Vector_LR1)*20)/20-.05, \n",
    "#               np.ceil(max(Error_Vector_LR1)*20)/20+.05])\n",
    "#axes.set_xlim(0, num_iter)\n",
    "axes.set_ylim(0,0.55)\n",
    "axes.set_xlim(0,200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unweighted version of the homegrown code has the lowest misclasiffication error at the 140th iteration (compared to the 2nd in the MLLib version), though it reaches convergence (based on the criterion previously described) before that, at the 136th iteration (compared to the 10th in the MLLib version).\n",
    "\n",
    "The hyperplane is not exaclty the true one (but that's highly dependent on the random datase we generated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.3.5\n",
    "**Weight the above training dataset as follows:  Weight each example using the inverse vector length (Euclidean norm):**\n",
    "        \n",
    "    weight(X)= 1/||X||\n",
    "\n",
    "**where**\n",
    "\n",
    "    ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n",
    "\n",
    "**Here X is vector made up of X1 and X2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To weight the training dataset we just have to apply the weights before calling the function defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readPoint_W(line):\n",
    "    d = line.split(',')\n",
    "    x = [float(i) for i in d[:2]]\n",
    "    x = list(x/np.sqrt(np.sum(np.array(x)**2)))\n",
    "    x.append(1.0)  #bias term\n",
    "    return Point(x, float(d[2]))\n",
    "\n",
    "train = sc.textFile('training_set.csv').map(readPoint_W).cache()\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "Error_Vector_LR2 = logRegressionGDReg(train, train, \n",
    "                                      iterations=200, regParam=0.01, \n",
    "                                      regType=\"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iter = len(Error_Vector_LR2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_LR2)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0,0.55)\n",
    "axes.set_xlim(0,200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted version converges at the 171st iteration (vs. 52nd in the unweighted version). And the minimum misclassification error (in the training set!) is achieved with quite less iterations: 21 instead of 140."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.3.6\n",
    "**Evaluate your homegrown weighted  LASSO logistic regression on the test dataset. Report misclassification error (1 - Accuracy) and how many iterations does it took to converge.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to use the testing set (instead of the training set) as the 2nd parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = sc.textFile('testing_set.csv').map(readPoint_W).cache()\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "Error_Vector_LR3 = logRegressionGDReg(train, test, \n",
    "                                      iterations=200, regParam=0.01, \n",
    "                                      regType=\"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iter = len(Error_Vector_LR3)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_LR3)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0,0.55)\n",
    "axes.set_xlim(0,250)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence criterion is again met at the 171st iteration (the initial weights are random, but we've used the same seed), and the minimum misclassification error (even in the testing set) is reached at the 20th iteration (21st in the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does Spark MLLib have a weighted LASSO logistic regression implementation. If so use it and report your findings on the weighted training set and test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I haven't found it, but it's just a matter of adapting the driver code a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, \\\n",
    "    LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import itertools\n",
    "\n",
    "iterations = 20\n",
    "## Define equally spaced colors for each iteration\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, iterations+1))\n",
    "\n",
    "def parsePoint_W(line):\n",
    "    ## Change labels to 0 and 1 (rather than -1 and 1)\n",
    "        ## Those are the values accepted by MLLib\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    x = list(values[:2]/np.sqrt(np.sum(np.array(values[:2])**2)))\n",
    "    if values[2] == -1:\n",
    "        y = 0\n",
    "    elif values[2] == 1:\n",
    "        y = 1\n",
    "    return LabeledPoint(y, x)\n",
    "\n",
    "## Load and cache both sets\n",
    "training = sc.textFile(\"training_set.csv\")\n",
    "testing = sc.textFile(\"testing_set.csv\")\n",
    "training = training.map(parsePoint_W).cache()\n",
    "testing = testing.map(parsePoint_W).cache()\n",
    "\n",
    "## Draw the true hyperplane\n",
    "x1 = [-1, 1]\n",
    "w = [-1, 1, 0]\n",
    "x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x1, x2, 'b', label=\"True line\", linewidth=2.0, color = 'black', \n",
    "         linestyle='--')\n",
    "\n",
    "prev_w = [float('inf')]*3\n",
    "#prev_Err = float('inf')\n",
    "\n",
    "## Try a few iterations (no need for more in this case)\n",
    "for it in range(iterations+1):\n",
    "    print 'Iteration: {}'.format(it)\n",
    "    # Build the model (Lasso/L1, lambda = 0.5)\n",
    "    model = LogisticRegressionWithLBFGS.train(training, regType=\"l1\", \n",
    "                                              regParam=0.01, \n",
    "                                              intercept = True, \n",
    "                                              iterations = it)\n",
    "    print model\n",
    "\n",
    "    # Evaluating the model on testing data\n",
    "    labelsAndPreds = testing.\\\n",
    "        map(lambda p: (p.label, model.predict(p.features)))\n",
    "    Err = labelsAndPreds.\\\n",
    "        filter(lambda (v, p): v != p).count() / float(testing.count())\n",
    "    w = [model.weights[0], model.weights[1], model.intercept]\n",
    "    x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "    ## Plot the hyperplanes\n",
    "    plt.plot(x1, x2, color=colors[it], label=\"After {} iterations\".\n",
    "             format(str(it)), linewidth=1.5)\n",
    "    \n",
    "    ## Stop when it converges\n",
    "    comb = [c for c in itertools.combinations(range(len(w)),2)]\n",
    "    ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) \n",
    "                               for (i,j) in comb])\n",
    "    condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "    if condition.all(axis=0):\n",
    "        break\n",
    "    \n",
    "    prev_w = w\n",
    "    #prev_Err = Err\n",
    "    print \"Testing Error: {}\".format(str(Err))\n",
    "    print '------------------'\n",
    "\n",
    "## Last iteration's results\n",
    "print \"Testing Error: {}\".format(str(Err))\n",
    "print '------------------'\n",
    "print 'CONVERGENCE AFTER {} ITERATIONS'.format(it)\n",
    "print 'Relative change of weights (incl. intercept) between iterations '\\\n",
    "    '{} and {}:\\n\\t{}'.format(it-1, it, [a/b for (a,b) in zip(w,prev_w)])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, borderaxespad=0.)\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-1,1])\n",
    "axes.set_xlim([-1,1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it takes a few more iterations to converge (14 vs. 9, still less than with the homegrown code), but the minimum misclassification error in the testing set is achieved even with just 1 iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW11.4: SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the non-linearly separable training and testing datasets from HW11.3 in this problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.4.1\n",
    "**Using MLLib  train up a soft SVM model with the training dataset and evaluate with the testing set. What is a good number of iterations for training the SVM model? Justify with plots and words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterion for convergence is the same as before. All the code is pretty much the same, we just have to use `SVMWithSGD` instead of `LogisticRegressionWithLBFGS`.\n",
    "\n",
    "This time I've chosen L2 regularization, the default for linear SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "iterations = 40\n",
    "## Define equally spaced colors for each iteration\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, iterations/2+1))\n",
    "\n",
    "def parsePoint(line):\n",
    "    ## Change labels to 0 and 1 (rather than -1 and 1)\n",
    "        ## Those are the values accepted by MLLib\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    if values[2] == -1:\n",
    "        y = 0\n",
    "    elif values[2] == 1:\n",
    "        y = 1\n",
    "    return LabeledPoint(y, values[:2])\n",
    "\n",
    "## Load and cache both sets\n",
    "training = sc.textFile(\"training_set.csv\")\n",
    "testing = sc.textFile(\"testing_set.csv\")\n",
    "training = training.map(parsePoint).cache()\n",
    "testing = testing.map(parsePoint).cache()\n",
    "\n",
    "## Draw the true hyperplane\n",
    "x1 = [-1, 1]\n",
    "w = [-1, 1, 0]\n",
    "x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x1, x2, 'b', label=\"True line\", linewidth=2.0, color = 'black', \n",
    "         linestyle='--')\n",
    "\n",
    "prev_w = [float('inf')]*3\n",
    "#prev_Err = float('inf')\n",
    "\n",
    "## Try a few iterations (no need for more in this case)\n",
    "for it in range(iterations+1):\n",
    "    print 'Iteration: {}'.format(it)\n",
    "    # Build the model (Lasso/L1, lambda = 0.5)\n",
    "    model = SVMWithSGD.train(training, regType=\"l2\", regParam=0.01, \n",
    "                             intercept = True, iterations = it)\n",
    "    print model\n",
    "\n",
    "    # Evaluating the model on testing data\n",
    "    labelsAndPreds = testing.\\\n",
    "        map(lambda p: (p.label, model.predict(p.features)))\n",
    "    Err = labelsAndPreds.\\\n",
    "        filter(lambda (v, p): v != p).count() / float(testing.count())\n",
    "    w = [model.weights[0], model.weights[1], model.intercept]\n",
    "    if it % 2 == 0 and it != 0:\n",
    "        x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "        ## Plot the hyperplanes\n",
    "        plt.plot(x1, x2, color=colors[it/2], label=\"After {} iterations\".\n",
    "                 format(str(it)), linewidth=1.5)\n",
    "    \n",
    "    comb = [c for c in itertools.combinations(range(len(w)),2)]\n",
    "    ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) \n",
    "                               for (i,j) in comb])\n",
    "    condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "    if condition.all(axis=0):\n",
    "        break\n",
    "    \n",
    "    prev_w = w\n",
    "    #prev_Err = Err\n",
    "    print \"Testing Error: {}\".format(str(Err))\n",
    "    print '------------------'\n",
    "\n",
    "## Last iteration's results\n",
    "print \"Testing Error: {}\".format(str(Err))\n",
    "print '------------------'\n",
    "print 'CONVERGENCE AFTER {} ITERATIONS'.format(it)\n",
    "print 'Relative change of weights (incl. intercept) between iterations '\\\n",
    "    '{} and {}:\\n\\t{}'.format(it-1, it, [a/b for (a,b) in zip(w,prev_w)])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, borderaxespad=0.)\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-1,1])\n",
    "axes.set_xlim([-1,1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes more iterations to converge than with the MLLib version of Logistic Regression: the minimum error is achieved at the 6th iteration, and the converge criterion is met at the 35th iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.4.2\n",
    "**Derive and Implement in Spark a weighted soft linear svm classification learning algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I define a general-purpose function that works with weighted or unweighted data, uses the convergence criterion describe previously, and so on. The main changes apply of course to the loss function, the gradient, and the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SVM_GDReg(training, testing, wInitial=None, \n",
    "                         learningRate=0.05, iterations=50, regParam=0.1):\n",
    "        \n",
    "    ## Draw the true hyperplane\n",
    "    x1 = [-1, 1]\n",
    "    w = [-1, 1, 0]\n",
    "    x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(x1, x2, 'b', label=\"True line\", linewidth=2.0, color = 'black', \n",
    "             linestyle='--')\n",
    "\n",
    "    featureLen = len(training.take(1)[0].x)\n",
    "    n = training.count()\n",
    "    if wInitial is None:\n",
    "        w = np.random.normal(size=featureLen)\n",
    "    else:\n",
    "        w = wInitial\n",
    "    prev_w = np.array([float('inf')]*featureLen)\n",
    "    #prev_Err = float('inf')\n",
    "    Err_vector = []\n",
    "    Num_SVs = []\n",
    "    convergence = False\n",
    "    \n",
    "    x1 = [-1,1]\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, iterations/10+1))\n",
    "    \n",
    "    for it in range(iterations+1):\n",
    "        wBroadcast = sc.broadcast(w)\n",
    "        sv = training.\\\n",
    "            filter(lambda p: p.y * np.dot(wBroadcast.value, p.x) < 1)\n",
    "            ## Only support vectors (label*margin) < 1\n",
    "        if sv.isEmpty(): ## Converged as no more updates possible\n",
    "            print 'No more support vectors at iteration {}'.\\\n",
    "                format(str(it))\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, \n",
    "                       borderaxespad=0.)\n",
    "            plt.xlabel(\"x1\")\n",
    "            plt.ylabel(\"x2\")\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,1])\n",
    "            axes.set_ylim([-1,1])\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            break ## Hinge loss component of gradient y*x and sum up \n",
    "        gradient = sv.map(lambda p: -p.y * np.array(p.x)).\\\n",
    "            reduce(lambda a,b: a + b) / n ## Gradient = average hinge loss\n",
    "        num_sv = sv.count()\n",
    "        \n",
    "        ## PREDICTIONS: sign(w^T*x)\n",
    "        errors = testing.\\\n",
    "            map(lambda p: p.y != np.sign(np.dot(wBroadcast.value, p.x))).\\\n",
    "            filter(lambda pred: pred == True).count()\n",
    "        Err = float(errors) / n\n",
    "        Err_vector.append(Err)\n",
    "        Num_SVs.append(num_sv)\n",
    "        \n",
    "        if Err == 0.1 and convergence == False:\n",
    "            print '+++++++++++++++++++++++++++++++++++++++'\n",
    "            print 'Minimum error achieved at iteration {}'.format(it)\n",
    "            print 'Ratio of weights at this iteration:'\n",
    "            print '\\t{}'.format(ratio_of_ratio)\n",
    "            print '+++++++++++++++++++++++++++++++++++++++'\n",
    "            convergence = True\n",
    "\n",
    "        wReg = w*1 ## wReg = w in Ridge/L2\n",
    "        wReg[-1] = 0\n",
    "        ## Gradient: hinge loss + regularized term \n",
    "        wDelta = learningRate*(gradient + regParam*wReg)\n",
    "\n",
    "        if it % 25 == 0 and it != 0:\n",
    "            print 'Iteration {}'.format(str(it))\n",
    "            print '\\tSupport vectors:\\t{}'.format(str(num_sv))\n",
    "            print '\\tWeights:\\t\\t{}'.format(w)\n",
    "            print '\\tError rate:\\t\\t{}'.format(str(Err))\n",
    "            print '----------------------------'\n",
    "            x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "            ## Plot the hyperplanes\n",
    "            plt.plot(x1, x2, color=colors[it/25], label=\"After {} iterations\".\n",
    "                 format(str(it)), linewidth=1.5)        \n",
    "        \n",
    "        comb = [c for c in itertools.combinations(range(len(w)),2)]\n",
    "        ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) \n",
    "                                   for (i,j) in comb])\n",
    "        condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "        if condition.all(axis=0):\n",
    "            if Err != 0.1 and convergence == False:\n",
    "                print '+++++++++++++++++++++++++++++++++++++++++++'\n",
    "                print 'Converge criterion met after {} iterations'\\\n",
    "                    'but lowest error not achieved yet.'.format(str(it))\n",
    "                print '+++++++++++++++++++++++++++++++++++++++++++'\n",
    "                convergence = True\n",
    "            else:\n",
    "                print 'Converged after {} iterations.'.format(str(it))\n",
    "                print '\\tSupport vectors:\\t{}'.format(str(num_sv))\n",
    "                print '\\tWeights:\\t\\t{}'.format(w)\n",
    "                print '\\tError rate:\\t\\t{}'.format(str(Err))\n",
    "                x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "                plt.plot(x1, x2, color='red', label=\"After {} iterations\".\n",
    "                         format(str(it)), linewidth=2.0)\n",
    "                plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, \n",
    "                           borderaxespad=0.)\n",
    "                plt.xlabel(\"x1\")\n",
    "                plt.ylabel(\"x2\")\n",
    "                axes = plt.gca()\n",
    "                axes.set_xlim([-1,1])\n",
    "                axes.set_ylim([-1,1])\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "                break\n",
    "        prev_w = w\n",
    "        w = w - wDelta\n",
    "        \n",
    "    return (Num_SVs, Err_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results using the unweighted data and checking the error in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = sc.textFile('training_set.csv').map(readPoint).cache()\n",
    "\n",
    "np.random.seed(12345)\n",
    "Error_Vector_SVM1 = SVM_GDReg(train, train, learningRate = 0.05, \n",
    "                              iterations=100, regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iter = len(Error_Vector_SVM1[0])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_SVM1[1])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0,0.55)\n",
    "axes.set_xlim(0,200)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_SVM1[0])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Number of Support Vectors\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0, 100)\n",
    "axes.set_xlim(0, 200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the MLLib version, which took more iterations to converge (compared to Logistic Regression), the homegrown code takes less: 49 to get the minimum misclassification error, and 66 to meet the convergence criterion that I defined. We end up with 50 support vectors (of the possible 100, though the 10 mislabeled points should not be support vectors at convergence).\n",
    "\n",
    "Let's see what happens when weights are applied (again, using the `readPoint_W` function and applying the weighted data to the ML function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = sc.textFile('training_set.csv').map(readPoint_W).cache()\n",
    "\n",
    "np.random.seed(12345)\n",
    "Error_Vector_SVM2 = SVM_GDReg(train, train, learningRate = 0.05, \n",
    "                              iterations=100, regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iter = len(Error_Vector_SVM2[0])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_SVM2[1])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0,0.55)\n",
    "axes.set_xlim(0,200)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_SVM2[0])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Number of Support Vectors\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0, 100)\n",
    "axes.set_xlim(0, 200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the SVM converges even faster: after 9 iterations we have an error (in the training set) of 10%, and with 53 we've met the convergence criterion.\n",
    "\n",
    "The number of support vectors with weighted data is reduced to 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.4.3\n",
    "**Evaluate your homegrown weighted soft linear svm classification learning algorithm on the weighted training dataset and test dataset from HW11.3. Report misclassification error (1 - Accuracy) and how many iterations does it took to converge?  How many support vectors do you end up?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = sc.textFile('testing_set.csv').map(readPoint_W).cache()\n",
    "\n",
    "np.random.seed(12345)\n",
    "Error_Vector_SVM3 = SVM_GDReg(train, test, learningRate = 0.05, \n",
    "                              iterations=100, regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iter = len(Error_Vector_SVM3[0])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_SVM3[1])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0,0.55)\n",
    "axes.set_xlim(0,200)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(num_iter), Error_Vector_SVM3[0])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Number of Support Vectors\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim(0, 100)\n",
    "axes.set_xlim(0, 200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the test set after 9 iterations (again) we get the lowest error possible: 10%. As mentioned in HW11.3, the iterations to meet the convergence criterion are the same than before because I used the same seed to generate the initial weights.\n",
    "\n",
    "Again (this depends on the convergence criterion, not on the training or testing error) we end up with only 25 support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW11.4.4\n",
    "**Does Spark MLLib have a weighted soft SVM learner. If so use it and report your findings on the weighted training set and test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Again, it doesn't seem so (http://apache-spark-user-list.1001560.n3.nabble.com/MLlib-weighted-training-td10291.html) but we can adapt the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import itertools\n",
    "\n",
    "iterations = 15\n",
    "## Define equally spaced colors for each iteration\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, iterations+1))\n",
    "\n",
    "def parsePoint_W(line):\n",
    "    ## Change labels to 0 and 1 (rather than -1 and 1)\n",
    "        ## Those are the values accepted by MLLib\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    x = list(values[:2]/np.sqrt(np.sum(np.array(values[:2])**2)))\n",
    "    if values[2] == -1:\n",
    "        y = 0\n",
    "    elif values[2] == 1:\n",
    "        y = 1\n",
    "    return LabeledPoint(y, x)\n",
    "\n",
    "## Load and cache both sets\n",
    "training = sc.textFile(\"training_set.csv\")\n",
    "testing = sc.textFile(\"testing_set.csv\")\n",
    "training = training.map(parsePoint_W).cache()\n",
    "testing = testing.map(parsePoint_W).cache()\n",
    "\n",
    "## Draw the true hyperplane\n",
    "x1 = [-1, 1]\n",
    "w = [-1, 1, 0]\n",
    "x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(x1, x2, 'b', label=\"True line\", linewidth=2.0, color = 'black', \n",
    "         linestyle='--')\n",
    "\n",
    "prev_w = [float('inf')]*3\n",
    "#prev_Err = float('inf')\n",
    "\n",
    "## Try a few iterations (no need for more in this case)\n",
    "for it in range(iterations+1):\n",
    "    print 'Iteration: {}'.format(it)\n",
    "    # Build the model (Lasso/L1, lambda = 0.5)\n",
    "    model = SVMWithSGD.train(training, regType=\"l2\", regParam=0.01, \n",
    "                             intercept = True, iterations = it)\n",
    "    print model\n",
    "\n",
    "    # Evaluating the model on testing data\n",
    "    labelsAndPreds = testing.\\\n",
    "        map(lambda p: (p.label, model.predict(p.features)))\n",
    "    Err = labelsAndPreds.\\\n",
    "        filter(lambda (v, p): v != p).count() / float(testing.count())\n",
    "    w = [model.weights[0], model.weights[1], model.intercept]\n",
    "    x2 = [-(i * w[0] + w[2]) / w[1] for i in x1]\n",
    "    ## Plot the hyperplanes\n",
    "    plt.plot(x1, x2, color=colors[it], label=\"After {} iterations\".\n",
    "             format(str(it)), linewidth=1.5)\n",
    "    \n",
    "    comb = [c for c in itertools.combinations(range(len(w)),2)]\n",
    "    ratio_of_ratio = np.array([(w[i]/prev_w[i])/(w[j]/prev_w[j]) \n",
    "                               for (i,j) in comb])\n",
    "    condition = (0.99<=ratio_of_ratio) & (ratio_of_ratio<=1.01)\n",
    "    if condition.all(axis=0):\n",
    "        break\n",
    "    \n",
    "    prev_w = w\n",
    "    #prev_Err = Err\n",
    "    print \"Testing Error: {}\".format(str(Err))\n",
    "    print '------------------'\n",
    "\n",
    "## Last iteration's results\n",
    "print \"Testing Error: {}\".format(str(Err))\n",
    "print '------------------'\n",
    "print 'CONVERGENCE AFTER {} ITERATIONS'.format(it)\n",
    "print 'Relative change of weights (incl. intercept) between iterations '\\\n",
    "    '{} and {}:\\n\\t{}'.format(it-1, it, [a/b for (a,b) in zip(w,prev_w)])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, fontsize=20, borderaxespad=0.)\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-1,1])\n",
    "axes.set_xlim([-1,1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY\n",
    "\n",
    "|LR|MLLib|homegrown|hw weighted|hw weighted w/ test|MLLib weighted|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|Iterations until Min. Error|2|140|21|20|1|\n",
    "|Iterations until Conv. crit.|10|136|171|171|14|\n",
    "\n",
    "|SVM|MLLib|homegrown|hw weighted|hw weighted w/ test|MLLib weighted|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|Iterations until Min. Error|6|49|9|9|2|\n",
    "|Iterations until Conv. crit.|35|66|53|53|10|\n",
    "|Support Vectors|-|50|25|25|-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
